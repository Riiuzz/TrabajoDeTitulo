# ğŸ“‹ Registro de Avances â€“ Active Research Bot

## Avance #1 â€“ ConfiguraciÃ³n Inicial y Prototipo Base
**Fecha:** Anterior a Diciembre 2025  
**Estado:** âœ… Completado

### DescripciÃ³n General
Desarrollo del prototipo inicial del bot con arquitectura bÃ¡sica frontend-backend integrada con Google Gemini API.

### Cambios Principales

#### âœ¨ Nuevas CaracterÃ­sticas
- **Chat conversacional bÃ¡sico** con interfaz flotante en React
- **ClasificaciÃ³n de intenciones** de usuario en 5 categorÃ­as:
  1. Preguntas sobre Active Research
  2. Preguntas sobre metodologÃ­a de investigaciÃ³n
  3. CotizaciÃ³n de proyectos
  4. Pulso Ciudadano y encuestas
  5. Preguntas fuera del scope
- **Respuesta inteligente** mediante Google Gemini API
- **Sistema de fallback** con respuestas predeterminadas cuando Gemini no estÃ¡ disponible
- **Persistencia de datos** en MongoDB con registro de todas las interacciones

#### ğŸ”§ Componentes Creados
```
backend/
  â”œâ”€â”€ app.py                    # Servidor Flask con endpoints de chat
  
frontend/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ App.js               # Componente principal
  â”‚   â”œâ”€â”€ App.css              # Estilos
  â”‚   â””â”€â”€ components/          # Componentes React del chat
  
  â””â”€â”€ public/
      â””â”€â”€ index.html           # HTML base
```

#### ğŸ› ï¸ TecnologÃ­as AÃ±adidas
- **Flask** â€“ Backend REST API
- **Flask-CORS** â€“ Manejo de CORS
- **React** â€“ Frontend SPA
- **MongoDB** â€“ Base de datos NoSQL
- **Google Generative AI** â€“ Modelo Gemini para clasificaciÃ³n y respuestas
- **python-dotenv** â€“ GestiÃ³n de variables de entorno

#### ğŸ” ConfiguraciÃ³n
- Variables de entorno: `GEMINI_API_KEY`, `MONGODB_URI`, `MONGODB_DBNAME`
- Puerto backend: `5000`
- Puerto frontend: `3000`
- CORS configurado para conexiÃ³n local

#### âš ï¸ Problemas Conocidos (Resueltos despuÃ©s)
- API Key comprometida (resuelta con nueva clave)
- Modelo de Gemini no disponible inicialmente
- MÃ©todo `datetime.utcnow()` deprecado

---

## Avance #2 â€“ IntegraciÃ³n de Web Scraping e Ãndice Local
**Fecha:** 1 de Diciembre 2025  
**Estado:** âœ… Completado

### DescripciÃ³n General
ImplementaciÃ³n de un sistema robusto de web scraping que descarga contenido en vivo del sitio de Activa Research y lo almacena en MongoDB como un "Ã­ndice local". El bot ahora consulta esta informaciÃ³n real para generar respuestas mÃ¡s precisas y actualizadas.

### Cambios Principales

#### âœ¨ Nuevas CaracterÃ­sticas
- **Web Scraping AutomÃ¡tico** â€“ Script que extrae contenido de 3 secciones clave de Activa Research:
  - Pulso Ciudadano
  - Estudios de OpiniÃ³n
  - QuiÃ©nes Somos
  
- **Ãndice Local en MongoDB** â€“ Almacenamiento de contenido scraped en colecciÃ³n `activa_content`

- **BÃºsqueda Contextual** â€“ El bot busca informaciÃ³n relevante en MongoDB y la pasa a Gemini como contexto

- **Respuestas MÃ¡s Precisas** â€“ Las categorÃ­as 1 (Activa) y 4 (Pulso Ciudadano) ahora incluyen datos reales del sitio

#### ğŸ”§ Componentes Creados/Modificados

**Nuevos archivos:**
```
backend/
  â”œâ”€â”€ scraper_activa.py        # Script de web scraping
  â””â”€â”€ .gitignore              # ProtecciÃ³n de archivos sensibles
```

**Modificados:**
```
backend/
  â””â”€â”€ app.py                  # IntegraciÃ³n de bÃºsqueda en MongoDB
                              # CorrecciÃ³n de datetime.utcnow()
                              # Nueva colecciÃ³n activa_content_col
```

#### ğŸ› ï¸ TecnologÃ­as AÃ±adidas
- **BeautifulSoup4** â€“ Parsing de HTML y extracciÃ³n de datos
- **requests** â€“ Descargas HTTP de pÃ¡ginas web
- **PyMongo** â€“ Operaciones adicionales en MongoDB
- **python-dotenv** â€“ Ya existente, mejorado para nuevo script

#### ğŸ“ Nuevas Funciones en `app.py`

```python
def buscar_contenido_activa(secciones: list, limite: int = 5) -> str
```
Busca contenido en MongoDB y lo formatea para pasar a Gemini como contexto.

#### ğŸ” Estructura de Datos en MongoDB

**ColecciÃ³n:** `activa_content`

```json
{
  "_id": ObjectId(...),
  "seccion": "pulso_ciudadano|estudios|quienes_somos",
  "contenido": {
    "type": "string",
    "titulo": "string",
    "descripcion": "string",
    "especialidades": ["array"],
    "enlace": "string",
    "fecha": "string"
  },
  "fecha_actualizacion": ISODate(...)
}
```

#### ğŸ”„ URLs Scrapeadas
| SecciÃ³n | URL |
|---------|-----|
| Pulso Ciudadano | https://chile.activasite.com/pulso-ciudadano/ |
| Estudios de OpiniÃ³n | https://chile.activasite.com/estudios-de-opinion/ |
| QuiÃ©nes Somos | https://chile.activasite.com/quienes-somos/ |

#### ğŸš€ CÃ³mo Usar el Scraper

```bash
cd backend
python scraper_activa.py
```

**Salida esperada:**
```
ğŸ”„ Iniciando descarga de contenido de Activa Research...
ğŸ“¥ Procesando: pulso_ciudadano
   URL: https://chile.activasite.com/pulso-ciudadano/
âœ… 1 documentos guardados para pulso_ciudadano
...
âœ… Descarga completada!
```

#### ğŸ”§ Integraciones Realizadas

1. **En `generar_respuesta_gemini()` â€“ CategorÃ­a 1:**
   - Busca contenido de "QuiÃ©nes Somos"
   - AÃ±ade informaciÃ³n real al contexto de Gemini

2. **En `generar_respuesta_gemini()` â€“ CategorÃ­a 4:**
   - Busca contenido de "Pulso Ciudadano" y "Estudios"
   - Proporciona estudios recientes al contexto

3. **ImportaciÃ³n de UTC:**
   - `from datetime import UTC`
   - ReemplazÃ³ `datetime.utcnow()` por `datetime.now(UTC)`

#### ğŸ—‘ï¸ Eliminaciones/Cambios Importantes

| Antes | DespuÃ©s | RazÃ³n |
|-------|---------|-------|
| `datetime.utcnow()` | `datetime.now(UTC)` | DeprecaciÃ³n en Python 3.12+ |
| Sin bÃºsqueda local | Con bÃºsqueda en MongoDB | Mayor precisiÃ³n en respuestas |
| Modelos `gemini-1.5-flash-latest` | `gemini-1.5-flash` | Compatibilidad con API |

#### âš¡ InstalaciÃ³n de Dependencias

```bash
pip install beautifulsoup4 requests pymongo python-dotenv
```

#### ğŸ“Š EstadÃ­sticas del Scraper

| MÃ©trica | Valor |
|---------|-------|
| URLs scrapeadas | 3 |
| Secciones indexadas | 3 |
| Documentos extraÃ­dos (promedio) | ~10 por secciÃ³n |
| Tiempo de ejecuciÃ³n | ~5-10 segundos |
| Frecuencia recomendada | Semanal |

#### ğŸ” Seguridad

- `.env` protegido en `.gitignore` (ya existente)
- Creado nuevo `.gitignore` en `backend/` con:
  - `venv/`, `__pycache__/`
  - `.env` y variantes
  - Carpetas de IDE (`.vscode/`, `.idea/`)

#### ğŸ“Œ Ventajas del Enfoque (OpciÃ³n 3)

âœ… InformaciÃ³n **actualizada y real**  
âœ… **RÃ¡pido** en tiempo de respuesta (sin latencia de scraping por solicitud)  
âœ… **Robusto** â€“ No depende de cambios en estructura HTML en tiempo real  
âœ… **Escalable** â€“ FÃ¡cil agregar mÃ¡s secciones  
âœ… **Flexible** â€“ InformaciÃ³n local, procesable por Gemini  

#### ğŸ”„ Flujo de EjecuciÃ³n Actualizado

```
1. Script scraper_activa.py (ejecutar 1x o periÃ³dicamente)
   â†“
2. Descarga HTML de 3 URLs de Activa Research
   â†“
3. Extrae y procesa contenido
   â†“
4. Guarda en MongoDB colecciÃ³n "activa_content"
   â†“
5. Usuario pregunta en el bot
   â†“
6. Bot clasifica la intenciÃ³n
   â†“
7. Bot busca en MongoDB si es categorÃ­a 1 o 4
   â†“
8. Bot pasa informaciÃ³n a Gemini como contexto
   â†“
9. Gemini genera respuesta basada en datos reales
   â†“
10. Respuesta entregada al usuario
```

#### ğŸ“ PrÃ³ximos Pasos Sugeridos

- [ ] Automatizar scraping con APScheduler (semanal)
- [ ] Mejorar parsing de HTML dinÃ¡mico con Selenium
- [ ] Agregar mÃ¡s secciones (servicios, clientes, etc.)
- [ ] Implementar bÃºsqueda full-text en MongoDB
- [ ] Cachear resultados de Gemini
- [ ] Panel de admin para visualizar Ã­ndice local
- [ ] Tests unitarios para scraper y bÃºsqueda

#### ğŸ› Problemas Resueltos en Este Avance

| Problema | SoluciÃ³n |
|----------|----------|
| Modelos de Gemini no encontrados | Cambiar a `gemini-1.5-flash` vÃ¡lido |
| API Key comprometida | Generar nueva clave en Google AI Studio |
| `datetime.utcnow()` deprecado | Usar `datetime.now(UTC)` |
| Bot sin contexto real | Implementar scraping e Ã­ndice local |
| Respuestas genÃ©ricas | Integrar bÃºsqueda en MongoDB |

---

## Resumen de Cambios Acumulados

### Archivos Modificados
- `app.py` â€“ AÃ±adida bÃºsqueda en MongoDB, correcciones de datetime
- `README.md` â€“ Este archivo de progreso

### Archivos Creados
- `scraper_activa.py` â€“ Web scraper con ParseJSoup
- `backend/.gitignore` â€“ ProtecciÃ³n mejorada
- `PROGRESS.md` â€“ Este registro de avances

### Dependencias AÃ±adidas (Avance #2)
- beautifulsoup4==4.14.3
- requests==2.32.5
- pymongo==4.15.4

### Base de Datos
- Nueva colecciÃ³n: `activa_content`
- Estructura: Documentos con secciones, contenido, y timestamps

---

## EstadÃ­sticas del Proyecto

| Aspecto | Avance #1 | Avance #2 | Total |
|---------|-----------|-----------|-------|
| Archivos Python | 1 | 2 | 3 |
| Endpoints REST | 1 | 1 | 1 |
| CategorÃ­as de clasificaciÃ³n | 5 | 5 | 5 |
| Colecciones MongoDB | 1 | 2 | 2 |
| Dependencias Python | 7 | 10 | 10 |
| LÃ­neas de cÃ³digo backend | ~550 | ~625 | ~625 |

---

## Notas Importantes

1. **Scraper Actual:** Extrae tÃ­tulos, descripciones y enlaces. Para informaciÃ³n mÃ¡s granular, puede mejorarse el parsing.

2. **Frecuencia de ActualizaciÃ³n:** Se recomienda ejecutar `scraper_activa.py` semanalmente o antes de cambios importantes en el sitio de Activa.

3. **Performance:** La bÃºsqueda local en MongoDB es mucho mÃ¡s rÃ¡pida que hacer scraping en cada solicitud.

4. **Contexto a Gemini:** El contenido buscado se pasa como contexto a Gemini, quien puede procesarlo y generar respuestas coherentes.

---

**Ãšltima actualizaciÃ³n:** 1 de Diciembre, 2025
